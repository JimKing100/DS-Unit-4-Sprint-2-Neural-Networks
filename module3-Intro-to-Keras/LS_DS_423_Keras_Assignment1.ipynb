{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer to array\n",
    "train = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 14) (51, 14)\n"
     ]
    }
   ],
   "source": [
    "# Train, test split\n",
    "train, test = train_test_split(train, train_size=0.90, test_size=0.10, random_state=42)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(train[:,0:13])\n",
    "Y = train[:,13]\n",
    "X_test = scaler.fit_transform(test[:,0:13])\n",
    "Y_test = test[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0204 16:56:32.796358 4708564416 deprecation.py:506] From /Users/JKMacBook/opt/anaconda3/envs/NN/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s 702us/sample - loss: 565.8196\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 82us/sample - loss: 458.1558\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 76us/sample - loss: 248.5469\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 92us/sample - loss: 79.6608\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 234us/sample - loss: 51.3742\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 291us/sample - loss: 34.5712\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 208us/sample - loss: 27.4973\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 111us/sample - loss: 24.4674\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 79us/sample - loss: 21.4877\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 74us/sample - loss: 20.1227\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 74us/sample - loss: 18.6678\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 74us/sample - loss: 17.8746\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 102us/sample - loss: 16.9358\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 80us/sample - loss: 16.4104\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 108us/sample - loss: 15.6944\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 75us/sample - loss: 15.3430\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 70us/sample - loss: 15.0594\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 75us/sample - loss: 14.8780\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 82us/sample - loss: 13.9101\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 109us/sample - loss: 13.7201\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 207us/sample - loss: 13.3570\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 144us/sample - loss: 12.9980\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 221us/sample - loss: 12.5997\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 136us/sample - loss: 12.5460\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 120us/sample - loss: 12.1124\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 101us/sample - loss: 12.1212\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 84us/sample - loss: 11.8475\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 78us/sample - loss: 11.7625\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 71us/sample - loss: 11.3573\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 72us/sample - loss: 10.9825\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 72us/sample - loss: 10.8247\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 71us/sample - loss: 10.4569\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 80us/sample - loss: 10.3252\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 89us/sample - loss: 10.2044\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 89us/sample - loss: 9.9786\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 107us/sample - loss: 9.8316\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 197us/sample - loss: 9.4588\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 208us/sample - loss: 9.2444\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 227us/sample - loss: 9.0297\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 186us/sample - loss: 8.8621\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 152us/sample - loss: 8.8385\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 109us/sample - loss: 8.5002\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 73us/sample - loss: 8.2231\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 92us/sample - loss: 8.0438\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 85us/sample - loss: 8.2677\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 98us/sample - loss: 8.1272\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 79us/sample - loss: 7.8599\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 98us/sample - loss: 7.5339\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 84us/sample - loss: 7.4879\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 108us/sample - loss: 7.2581\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 190us/sample - loss: 7.6297\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 178us/sample - loss: 7.2831\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 197us/sample - loss: 7.0383\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 200us/sample - loss: 7.0131\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 136us/sample - loss: 6.8588\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 127us/sample - loss: 6.5072\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 101us/sample - loss: 6.4533\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 97us/sample - loss: 6.2726\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 93us/sample - loss: 6.2307\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 121us/sample - loss: 6.3052\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 100us/sample - loss: 6.1889\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 131us/sample - loss: 5.9069\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 179us/sample - loss: 5.9038\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 227us/sample - loss: 6.0722\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 173us/sample - loss: 5.8822\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 186us/sample - loss: 5.5918\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 180us/sample - loss: 5.5017\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 140us/sample - loss: 5.5168\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 205us/sample - loss: 5.3440\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 151us/sample - loss: 5.3612\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 198us/sample - loss: 5.3899\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 174us/sample - loss: 5.2130\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 167us/sample - loss: 5.1871\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 129us/sample - loss: 5.3322\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 109us/sample - loss: 5.1420\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 89us/sample - loss: 5.0946\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 80us/sample - loss: 5.0888\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 81us/sample - loss: 5.0839\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 84us/sample - loss: 5.2048\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 83us/sample - loss: 4.8634\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 86us/sample - loss: 4.8454\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 87us/sample - loss: 4.6314\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 111us/sample - loss: 4.8237\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 78us/sample - loss: 4.6174\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 97us/sample - loss: 4.6154\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 95us/sample - loss: 4.6969\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 115us/sample - loss: 4.6323\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 123us/sample - loss: 4.3326\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 125us/sample - loss: 4.6944\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 90us/sample - loss: 4.4470\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 105us/sample - loss: 4.4394\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 86us/sample - loss: 4.3193\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 131us/sample - loss: 4.3148\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 137us/sample - loss: 4.1134\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 92us/sample - loss: 4.1971\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 86us/sample - loss: 4.2017\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 91us/sample - loss: 4.0448\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 97us/sample - loss: 3.9412\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 85us/sample - loss: 4.0255\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 77us/sample - loss: 4.2377\n"
     ]
    }
   ],
   "source": [
    "# Fit the data and record the history\n",
    "history = model.fit(\n",
    "                    X,\n",
    "                    Y,\n",
    "                    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/sample - loss: 16.1365\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the score (loss = MSE at compile time)\n",
    "scores = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss-MSE value\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 14) (51, 14)\n",
      "Test Mean Squared Error: 14.99585287658263\n",
      "Test Mean Absolute Error: 2.8342104578589704\n",
      "Test R^2: 0.7598135533532476\n"
     ]
    }
   ],
   "source": [
    "# Run the data in a linear regression model\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Encode and fit a linear regression model\n",
    "train, test = train_test_split(df, train_size=0.90, test_size=0.10, random_state=42)\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "target = 'medv'\n",
    "X_train = train.drop(target, axis=1).values\n",
    "y_train = train[[target]].values\n",
    "X_test = test.drop(target, axis=1).values\n",
    "y_test = test[[target]].values\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "  SimpleImputer(strategy='mean'),\n",
    "  LinearRegression()\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "ty_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print regression metrics for test\n",
    "test_mse = mean_squared_error(y_test, ty_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, ty_pred)\n",
    "test_r2 = r2_score(y_test, ty_pred)\n",
    "print('Test Mean Squared Error:', test_mse)\n",
    "print('Test Mean Absolute Error:', test_mae)\n",
    "print('Test R^2:', test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "((X_train, y_train), (X_test, y_test)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# Reshape the data\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "# X Variable Types\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,546\n",
      "Trainable params: 13,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model = Sequential()\n",
    "\n",
    "# Input => Hidden\n",
    "mnist_model.add(Dense(16, input_dim=784, activation='relu'))\n",
    "# Hidden\n",
    "mnist_model.add(Dense(16, activation='relu'))\n",
    "# Hidden\n",
    "mnist_model.add(Dense(16, activation='relu'))\n",
    "# Hidden\n",
    "mnist_model.add(Dense(16, activation='relu'))\n",
    "# Output\n",
    "mnist_model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "#Compile\n",
    "mnist_model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X):\n",
    "    \n",
    "    dense1 = Dense(8, activation='relu', input=X)\n",
    "    dense2 = Dense(8, activation='relu')(X)\n",
    "    \n",
    "    \n",
    "    return dense2 #or return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.6289 - acc: 0.7682\n",
      "acc: 76.81999802589417\n"
     ]
    }
   ],
   "source": [
    "history = mnist_model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=False)\n",
    "scores = mnist_model.evaluate(X_test, y_test)\n",
    "print(f'{mnist_model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
